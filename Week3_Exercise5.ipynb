{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week3-Exercise5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sniggel/colab-repo/blob/master/Week3_Exercise5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "oJrviE4Sp8Pw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "9bf1c02e-c955-4a7e-e8aa-4438f19a693e"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "print(tf.__version__)\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    # when loss is below 0.99 stop\n",
        "    if(logs.get('acc')>=0.90):\n",
        "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "## Load MNIST\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "## Give a new shape to the array without changing its data.\n",
        "## where: 60000 = nbInTrainingSet, 28 = width, 28 = height, 1 is dimension\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "\n",
        "## Give a new shape to the array without changing its data.\n",
        "## where: 10000 = nbInTestgSet, 28 = width, 28 = height, 1 is dimension\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  ## Add an initial 3*3 convolution layer\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  ## Add a 2*2 hidden pooling layer, reducing the image size by half\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  ## Add a 3*3 hidden convolution layer, relu returns 0 on negative values\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  ## Add a 2*2 hidden pooling layer, reducing the image size by half\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  ## Flattens the images to a 1D array (as we can see in the summary: (None, 1600) )\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "## Display the size and shape of the network, notice the image is reduced after\n",
        "## every MaxPooling layer\n",
        "model.summary()\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)\n",
        "\n",
        "## Prints the first 100 labels in the test set\n",
        "print(test_labels[:100])\n",
        "\n",
        "## In the previous lesson you implemented a callback to check on the loss\n",
        "## function and to cancel training once it hit a certain amount.\n",
        "## See if you can implement that here!\n",
        "\n",
        "## Answer:\n",
        "## Done, I used greater than or equal to 90% accuracy."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 106s 2ms/sample - loss: 0.4367 - acc: 0.8429\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 104s 2ms/sample - loss: 0.2934 - acc: 0.8921\n",
            "Epoch 3/5\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.2494 - acc: 0.9075\n",
            "Reached 99% accuracy so cancelling training!\n",
            "60000/60000 [==============================] - 106s 2ms/sample - loss: 0.2493 - acc: 0.9075\n",
            "10000/10000 [==============================] - 5s 486us/sample - loss: 0.2746 - acc: 0.8976\n",
            "0.8976\n",
            "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
            " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
            " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KWDPEcstDhmM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PIMwT7nlsL9k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}